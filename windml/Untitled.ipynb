{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1830)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%############################################################################ imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "home=os.path.expanduser(\"~/\")\n",
    "os.chdir(home)\n",
    "\n",
    "#%%############################################################################# SVM\n",
    "\n",
    "# select path and file\n",
    "path = '/home/romeo/Nextcloud/RI-Romeo/WindML/Data/'\n",
    "file = 'Wav1'\n",
    "\n",
    "# read and rescale image / spectrogram\n",
    "XX = plt.imread(path+file+'.png').T/255.0\n",
    "ly,lx= XX.shape\n",
    "\n",
    "# read manual classification data\n",
    "YY = np.array(pd.read_csv(path+file+'.txt')['Status'])\n",
    "\n",
    "# set labels of different noises\n",
    "labels = {1:'normal', 2:'other', 3:'vehicles', 4:'voices', 5:'setup', 6:'airplanes'}\n",
    "\n",
    "#%%# plot data\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.imshow(XX.T, cmap='Greys', interpolation='nearest', aspect='auto', extent=[0,lx,0,ly])\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('frequency')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(YY, ls='', marker='o', color='red', label='manual')\n",
    "plt.legend(loc=0)\n",
    "plt.ylabel('class')\n",
    "plt.yticks(list(labels.keys()),list(labels.values()))\n",
    "plt.xlim(0,lx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1830)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%############################################################################ imports\n",
    "\n",
    "import copy\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn.discriminant_analysis\n",
    "import sklearn.externals\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "import sklearn.neural_network\n",
    "import sklearn.svm\n",
    "import sklearn.tree\n",
    "import sklearn.utils\n",
    "\n",
    "home=os.path.expanduser(\"~/\")\n",
    "os.chdir(home)\n",
    "\n",
    "#%%############################################################################# SVM\n",
    "\n",
    "# select path and file\n",
    "path = '/home/romeo/Nextcloud/RI-Romeo/WindML/Data/'\n",
    "file = 'Wav1'\n",
    "\n",
    "# read and rescale image / spectrogram\n",
    "XX = plt.imread(path+file+'.png').T/255.0\n",
    "ly,lx= XX.shape\n",
    "\n",
    "# read manual classification data\n",
    "YY = np.array(pd.read_csv(path+file+'.txt')['Status'])\n",
    "\n",
    "# set labels of different noises\n",
    "labels = {1:'normal', 2:'other', 3:'vehicles', 4:'voices', 5:'setup', 6:'airplanes'}\n",
    "\n",
    "#%%# plot data\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.imshow(XX.T, cmap='Greys', interpolation='nearest', aspect='auto', extent=[0,lx,0,ly])\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('frequency')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(YY, ls='', marker='o', color='red', label='manual')\n",
    "plt.legend(loc=0)\n",
    "plt.ylabel('class')\n",
    "plt.yticks(list(labels.keys()),list(labels.values()))\n",
    "plt.xlim(0,lx)\n",
    "\n",
    "#%%# set metric for measuring classification quality\n",
    "\n",
    "metric = sklearn.metrics.jaccard_similarity_score\n",
    "\n",
    "# set size/fraction of training and test sets\n",
    "train_size = 0.5\n",
    "test_size = 0.2\n",
    "\n",
    "# split data into training (0) and test set (1)\n",
    "X0,X1,Y0,Y1 = sklearn.model_selection.train_test_split(XX, YY, train_size=train_size, test_size=test_size)\n",
    "\n",
    "# multilayer  perceptron\n",
    "# theano + lasagne\n",
    "# train SVM, may take a few seconds\n",
    "svc = sklearn.svm.SVC(gamma=1.0, C=1.0).fit(X0, Y0)\n",
    "\n",
    "# predict classes for complete data\n",
    "yy = svc.predict(XX)\n",
    "\n",
    "# prediction quality\n",
    "q = metric(yy, YY)\n",
    "\n",
    "#%%# plot\n",
    "\n",
    "plt.plot(YY, ls='', marker='o', color='red', label='manual')\n",
    "plt.plot(yy+0.1, ls='', marker='o', color='orange', label='prediction') # shift for better visibility\n",
    "\n",
    "plt.title('quality = '+'%.2f'%q)\n",
    "plt.legend(loc=0)\n",
    "plt.ylabel('class')\n",
    "plt.yticks(list(labels.keys()),list(labels.values()))\n",
    "plt.xlim(0,lx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '-f', '/run/user/1001/jupyter/kernel-b5e68f30-b0fd-4186-96ab-135aed02ffa1.json']\n",
      "0 2 0 4 0 3\n",
      "0 2 0 4 1 3\n",
      "0 2 0 4 2 3\n",
      "0 2 1 4 0 3\n",
      "0 2 1 4 1 3\n",
      "0 2 1 4 2 3\n",
      "0 2 2 4 0 3\n",
      "0 2 2 4 1 3\n",
      "0 2 2 4 2 3\n",
      "0 2 3 4 0 3\n",
      "0 2 3 4 1 3\n",
      "0 2 3 4 2 3\n",
      "1 2 0 4 0 3\n",
      "1 2 0 4 1 3\n",
      "1 2 0 4 2 3\n",
      "1 2 1 4 0 3\n",
      "1 2 1 4 1 3\n",
      "1 2 1 4 2 3\n",
      "1 2 2 4 0 3\n",
      "1 2 2 4 1 3\n",
      "1 2 2 4 2 3\n",
      "1 2 3 4 0 3\n",
      "1 2 3 4 1 3\n",
      "1 2 3 4 2 3\n"
     ]
    }
   ],
   "source": [
    "#%%############################################################################ imports\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sp\n",
    "import sys\n",
    "import time\n",
    "\n",
    "home=os.path.expanduser(\"~/\")\n",
    "os.chdir(home)\n",
    "\n",
    "#%%############################################################################ test functions\n",
    "\n",
    "def func_sleep(T):\n",
    "    time.sleep(1.0/T) # 10\n",
    "    return None\n",
    "\n",
    "def func_matrix(T):\n",
    "    for k in range(int(100/T)): # 1000\n",
    "        a=sp.rand(100,100)\n",
    "        a=a**5\n",
    "    return None\n",
    "\n",
    "#%%############################################################################ function for testing speed gain due to parallelization\n",
    "\n",
    "def multi():\n",
    "    \n",
    "    #%%# parameters\n",
    "    \n",
    "    F=2 # different functions\n",
    "    C=4 # number of cores\n",
    "    I=3 # iterations\n",
    "    T=1 # chunk number # 1/100 is good/bad for parallelization\n",
    "\n",
    "    functions=[func_sleep,func_matrix]\n",
    "    \n",
    "    #%%# auxiliary variables\n",
    "    \n",
    "    FF=range(F)\n",
    "    CC=range(1,C+1)\n",
    "    II=range(I)\n",
    "    TT=range(T)\n",
    "\n",
    "    duration=np.zeros((F,C,I))*np.nan\n",
    "\n",
    "    #%%# loop over parameters and functions\n",
    "\n",
    "    for fi,f in enumerate(FF):\n",
    "        for ci,c in enumerate(CC):\n",
    "            for ii,i in enumerate(II):\n",
    "                print(fi,F,ci,C,ii,I)\n",
    "                func=functions[fi]\n",
    "                temp=time.time()\n",
    "                joblib.Parallel(n_jobs=c)(joblib.delayed(func)(T) for t in TT)\n",
    "                duration[fi,ci,ii]=time.time()-temp\n",
    "\n",
    "    #%%# plot computation times\n",
    "\n",
    "    for fi,f in enumerate(FF):\n",
    "\n",
    "        color='C'+str(fi)\n",
    "        label=str(functions[fi].__name__)\n",
    "\n",
    "        mu=np.nanmean(1.0/duration[fi],-1)\n",
    "        sd=np.nanstd(1.0/duration[fi],-1)\n",
    "        ln=mu[0]*np.array(CC)\n",
    "\n",
    "        plt.fill_between(CC,mu-sd,mu+sd,lw=0,color=color,alpha=0.5)\n",
    "        plt.plot(CC,mu,lw=2,ls='-',color=color,label=label)\n",
    "        plt.plot(CC,ln,lw=2,ls='--',color=color)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xticks(CC,CC)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.xlabel('cores')\n",
    "    plt.ylabel('calls per second')\n",
    "    plt.savefig('multi.png')\n",
    "\n",
    "#%%############################################################################ run script with dummy arguments\n",
    "\n",
    "args=sys.argv\n",
    "print(args)\n",
    "multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'method' and 'method'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-70c423a71ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memplike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkoul_and_mc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwindml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/statsmodels/emplike/koul_and_mc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmc_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gives MC parameter estimate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m##################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2909\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'method' and 'method'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#%%############################################################################ imports\n",
    "\n",
    "import copy\n",
    "import inspect\n",
    "import tempfile\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "import shutil\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn.discriminant_analysis\n",
    "import sklearn.externals\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "import sklearn.neural_network\n",
    "import sklearn.svm\n",
    "import sklearn.tree\n",
    "import sklearn.utils\n",
    "#-----------------------------------------------------\n",
    "import skimage\n",
    "#_____________________________________________________\n",
    "\n",
    "#%%############################################################################# definitions\n",
    "import time\n",
    "\n",
    "from statsmodels.emplike.koul_and_mc import params\n",
    "\n",
    "from windml.example import Y1\n",
    "\n",
    "\n",
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "\n",
    "\n",
    "def class_quality(real,pred):\n",
    "    jac=sklearn.metrics.jaccard_similarity_score(real,pred)\n",
    "    acc=sklearn.metrics.accuracy_score(real,pred)\n",
    "    ham=1.0-sklearn.metrics.hamming_loss(real,pred)\n",
    "    pre=sklearn.metrics.precision_score(real,pred,average='weighted')\n",
    "    rec=sklearn.metrics.recall_score(real,pred,average='weighted')\n",
    "    fis=sklearn.metrics.f1_score(real,pred,average='weighted')\n",
    "    cor=sp.stats.pearsonr(real,pred)[0]\n",
    "    return jac,acc,ham,pre,rec,fis,cor\n",
    "\n",
    "def call_with_kwargs(func,kwargs,para=None): # kwargs={**kwargs,**kwargz}\n",
    "    params=inspect.getargspec(func).args\n",
    "    dicts={k: v for k,v in kwargs.items() if k in params}\n",
    "    if(para==None):\n",
    "        f=func(**dicts)\n",
    "    else:\n",
    "        f=func(*para,**dicts)\n",
    "    return f\n",
    "\n",
    "def downsample_image(XX,downs=1,speed=1):\n",
    "    X=np.vstack([XX[:,:speed].T,skimage.transform.resize(XX[:,speed:],(len(XX),int((len(XX[0])-speed)/downs))).T]).T\n",
    "    return X\n",
    "\n",
    "def stripe_image(X,Y,breadth=1):\n",
    "    lx=len(Y)\n",
    "    x=[]\n",
    "    y=Y[0:lx-breadth+1]\n",
    "    for i in range(lx-breadth+1):\n",
    "        x.append(X[i:i+breadth].ravel())\n",
    "    x=np.array(x)\n",
    "    return x,y\n",
    "\n",
    "def binarize_image(YY, multi=1, Y=None):\n",
    "    if(multi):\n",
    "        Y=YY\n",
    "    else:\n",
    "        Y=1*(Y>0)\n",
    "    return Y\n",
    "\n",
    "def grid_search(XX,YY,params,order,n_jobs=2,test_size=0.2,clf=sklearn.svm.SVC,metric=sklearn.metrics.jaccard_similarity_score):\n",
    "\n",
    "    keys=list(params.keys())\n",
    "    vals=list(params.values())\n",
    "    values=[{keys[ji]:j for ji,j in enumerate(k)} for k in np.itertools.product(*vals)]\n",
    "    idcs=[range(len(v)) for v in vals]\n",
    "    indics=[{keys[ji]:j for ji,j in enumerate(k)} for k in np.itertools.product(*idcs)]\n",
    "    V=len(values)\n",
    "\n",
    "    quali=np.zeros([len(params[o]) for o in order])*np.nan\n",
    "    qualt=np.zeros([len(params[o]) for o in order])*np.nan\n",
    "\n",
    "    path = tempfile.mkdtemp()\n",
    "    memoi = os.path.join(path,'memoi.mmap')\n",
    "    memot = os.path.join(path,'memot.mmap')\n",
    "    quali = np.memmap(memoi, dtype=quali.dtype, shape=quali.shape, mode='w+')\n",
    "    qualt = np.memmap(memot, dtype=qualt.dtype, shape=qualt.shape, mode='w+')\n",
    "\n",
    "    joblib.Parallel(n_jobs=n_jobs)(joblib.delayed(simple_search)(XX,YY,v,clf,order,indics,test_size,metric,vi,V,quali,qualt) for vi,v in enumerate(values))\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    mu=np.nanmean(quali,0)\n",
    "    sd=np.nanstd(quali,0)\n",
    "    idm=np.unravel_index(np.nanargmax(mu),mu.shape)\n",
    "    valui={o:params[o][idm[oi]] for oi,o in enumerate(order[1:])}\n",
    "\n",
    "    mu=np.nanmean(qualt,0)\n",
    "    sd=np.nanstd(qualt,0)\n",
    "    idm=np.unravel_index(np.nanargmax(mu),mu.shape)\n",
    "    valut={o:params[o][idm[oi]] for oi,o in enumerate(order[1:])}\n",
    "\n",
    "    X=downsample_image(XX,downs=valui['downs'],speed=valui['speed'])\n",
    "    X,Y=stripe_image(X,YY,breadth=valui['brdth'])\n",
    "    Y=binarize_image(Y,multi=valui['multi'])\n",
    "\n",
    "    return X,Y,quali,valui,qualt,valut\n",
    "\n",
    "def simple_search(XX,YY,value,clf,order,indics,test_size,metric,vi,V,quali,qualt):\n",
    "\n",
    "    dd=value['downs']\n",
    "    ii=value['iters']\n",
    "    ss=value['speed']\n",
    "    mm=value['multi']\n",
    "    bb=value['brdth']\n",
    "\n",
    "    X=downsample_image(XX,downs=dd,speed=ss)\n",
    "    X,Y=stripe_image(X,YY,breadth=bb)\n",
    "    Y=binarize_image(Y,multi=mm)\n",
    "\n",
    "    fnc=call_with_kwargs(clf,value)\n",
    "    idv=indics[vi]\n",
    "    idx=[idv[o] for o in order]\n",
    "\n",
    "    temp=time.time()\n",
    "    Y0=[0]\n",
    "    while(set(Y)!=set(Y0)):\n",
    "        X0,X1,I0,I1=sklearn.model_selection.train_test_split(X,np.array(range(len(Y))),train_size=value['train_size'],test_size=test_size)\n",
    "        Y0,Y1=Y[I0],Y[I1]\n",
    "    fnc.fit(X0,Y0)\n",
    "    y1=fnc.predict(X1)\n",
    "    dura=(time.time()-temp)/60.0\n",
    "    quali[tuple(idx)]=metric(Y1,y1)\n",
    "    qualt[tuple(idx)]=dura\n",
    "    print(vi,V,dura,X.shape,value)\n",
    "\n",
    "    return None\n",
    "\n",
    "def sliding_ensemble_quality(Y1,y1,window=3,weighted=1):\n",
    "    labs=sorted(list(set(Y1)))\n",
    "    freq=np.array([(Y1==l).sum() for l in labs])\n",
    "    freq=1.0*freq/np.nansum(freq)\n",
    "    z=Y1.copy()\n",
    "    if(len(y1.shape)==1):\n",
    "        yy=np.array([y1])\n",
    "    else:\n",
    "        yy=y1\n",
    "    lx=len(y1)\n",
    "    for ii,i in enumerate(y1):\n",
    "        xmi,xma=max(0,ii-window),min(lx,ii+window+1)\n",
    "        freqs=np.array([(yy[:,xmi:xma]==l).sum() for l in labs])\n",
    "        freqs=1.0*freqs/np.nansum(freqs)\n",
    "        if(weighted):\n",
    "            ratio=1.0*freqs/freq                                                    # weighted majority voting\n",
    "        else:\n",
    "            ratio=freqs\n",
    "        ratio[~np.isfinite(ratio)]=0\n",
    "        z[ii]=np.nanargmax(ratio)\n",
    "    return z\n",
    "\n",
    "def window_search(X,Y,value,windows,test_size=0.2,clf=sklearn.svm.SVC,metric=sklearn.metrics.jaccard_similarity_score):\n",
    "    Y0=[0]\n",
    "    while(set(Y)!=set(Y0)):\n",
    "        X0,X1,I0,I1=sklearn.model_selection.train_test_split(X,np.array(range(len(Y))),train_size=value['train_size'],test_size=test_size)\n",
    "        Y0,Y1=Y[I0],Y[I1]\n",
    "    fnc=call_with_kwargs(clf,value)\n",
    "    fnc.fit(X0,Y0)\n",
    "    y=fnc.predict(X)\n",
    "    qs=np.zeros(len(windows))\n",
    "    for wi,w in enumerate(windows):\n",
    "        z=sliding_ensemble_quality(Y,y,window=w)\n",
    "        qs[wi]=metric(z,Y)\n",
    "    window=windows[np.nanargmax(qs)]\n",
    "    z=sliding_ensemble_quality(Y,y,window=window)\n",
    "    qy0=metric(y[I0],Y[I0])\n",
    "    qy1=metric(y[I1],Y[I1])\n",
    "    qz0=metric(z[I0],Y[I0])\n",
    "    qz1=metric(z[I1],Y[I1])\n",
    "    copt=copy.deepcopy(fnc)\n",
    "    return copt,qs,window,y,z,qy0,qy1,qz0,qz1,I0,I1\n",
    "\n",
    "def random_quality(Y,R,metric=sklearn.metrics.jaccard_similarity_score):\n",
    "    y=Y.copy()\n",
    "    q=[]\n",
    "    for r in range(R):\n",
    "        random.shuffle(y)\n",
    "        q.append(metric(y,Y))\n",
    "    return np.array(q)\n",
    "\n",
    "def plot_multi_label(ss,Y,offset,width,label=0,alpha=0.8):\n",
    "    S=len(ss)\n",
    "    ll=range(len(Y))\n",
    "    for si,s in enumerate(ss):\n",
    "        color=plt.cm.rainbow(si/(S-1.0))\n",
    "        if(label):\n",
    "            plt.fill_between(ll,width*(si+offset),width*(si+offset+1),where=(Y==s),color=color,alpha=alpha,label=ss[si],lw=0)\n",
    "        else:\n",
    "            plt.fill_between(ll,width*(si+offset),width*(si+offset+1),where=(Y==s),color=color,alpha=alpha,lw=0)\n",
    "    return None\n",
    "\n",
    "def plot_overview(X,Y,quali,value,windows,labels,order,test_size=0.2,ylabel='quality',clf=sklearn.svm.SVC,metric=sklearn.metrics.jaccard_similarity_score):\n",
    "\n",
    "    mu=np.nanmean(quali,0)\n",
    "    sd=np.nanstd(quali,0)\n",
    "    idm=np.unravel_index(np.nanargmax(mu),mu.shape)\n",
    "\n",
    "\n",
    "    P=max(len([i for i in mu.shape if i>1]),5)\n",
    "    L=len(labels.keys())\n",
    "    lx,ly=X.shape\n",
    "    T=int(lx*value['train_size'])\n",
    "    plt.clf()\n",
    "    count=-1\n",
    "    for ji,j in enumerate(mu.shape):\n",
    "        if(j==1):\n",
    "            continue\n",
    "        count+=1\n",
    "        plt.subplot(2,P,1+count)\n",
    "        idj=[i for i in idm]\n",
    "        idj[ji]=slice(None)\n",
    "        mux=mu[tuple(idj)]\n",
    "        sdx=sd[tuple(idj)]\n",
    "        o=order[1:][ji]\n",
    "        xx=params[o]\n",
    "        plt.title(xx[idm[ji]])\n",
    "        if(type(xx[0])==str or type(xx[0])==tuple):\n",
    "            xx=range(len(xx))\n",
    "        plt.fill_between(xx,mux-sdx,mux+sdx,lw=0,color='LightGray')\n",
    "        plt.plot(xx,mux,color='black',lw=2)\n",
    "        plt.scatter(xx[idm[ji]],mux[idm[ji]],color='purple',marker='o',zorder=9)\n",
    "        plt.xlabel(o)\n",
    "        plt.ylabel(ylabel)\n",
    "        if(o=='C' or o=='gamma' or o=='alpha'):\n",
    "            plt.xscale('log')\n",
    "\n",
    "    copt,qs,window,y,z,qy0,qy1,qz0,qz1,I0,I1=window_search(X,Y,value,windows,clf=clf,metric=metric,test_size=test_size)\n",
    "\n",
    "    qr=random_quality(Y1,200,metric=metric)\n",
    "\n",
    "    plt.subplot(2,P,2*P-4)\n",
    "    plt.title(window)\n",
    "    plt.plot(windows,qs,lw=2,color='black')\n",
    "    plt.scatter(window,max(qs),marker='o',color='purple',zorder=9)\n",
    "    plt.xlabel('window')\n",
    "    plt.ylabel('quality')\n",
    "\n",
    "    plt.subplot(2,P,2*P-3)\n",
    "    plt.title('%.3f'%np.nanmean(qr))\n",
    "    hh=plt.hist(qr,bins=30,histtype='step',lw=2,color='gray',normed=1)\n",
    "    plt.plot([qy0]*2,[0,max(hh[0])*0.9],lw=2,color='black',ls='--')\n",
    "    plt.plot([qz0]*2,[0,max(hh[0])*0.9],lw=2,color='black')\n",
    "    plt.plot([qy1]*2,[0,max(hh[0])*0.8],lw=2,color='purple',ls='--')\n",
    "    plt.plot([qz1]*2,[0,max(hh[0])*0.8],lw=2,color='purple')\n",
    "    plt.xlabel(ylabel)\n",
    "    plt.ylabel('probability')\n",
    "\n",
    "    plt.subplot(2,P,2*P-2)\n",
    "    plt.title('train '+'%.3f'%qy0+' '+'%.3f'%qz0+'\\n test '+'%.3f'%qy1+' '+'%.3f'%qz1)\n",
    "    plt.imshow(X.T,origin='upper',interpolation='nearest',cmap='gray',aspect='auto')\n",
    "    plot_multi_label(labels,Y,(L+2)*0,ly*0.02,alpha=0.6,label=1)\n",
    "    plot_multi_label(labels,y,(L+2)*1,ly*0.02,alpha=0.6,label=0)\n",
    "    plot_multi_label(labels,z,(L+2)*2,ly*0.02,alpha=0.6,label=0)\n",
    "    plt.plot([lx*T]*2,[0,ly],lw=2,color='white',ls='-')\n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0,lx,ly,0])\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('frequency')\n",
    "\n",
    "    plt.subplot(2,P,2*P-1)\n",
    "    plt.title('train confusion matrix')\n",
    "    mat=sklearn.metrics.confusion_matrix(Y[I0],z[I0])\n",
    "    plt.imshow(mat,origin='upper',interpolation='nearest',cmap='gray',aspect='auto')\n",
    "    plt.xlabel('real')\n",
    "    plt.ylabel('pred')\n",
    "\n",
    "    plt.subplot(2,P,2*P-0)\n",
    "    plt.title('test confusion matrix')\n",
    "    mat=sklearn.metrics.confusion_matrix(Y[I1],z[I1])\n",
    "    plt.imshow(mat,origin='upper',interpolation='nearest',cmap='gray',aspect='auto')\n",
    "    plt.xlabel('real')\n",
    "    plt.ylabel('pred')\n",
    "\n",
    "    return copt,window,value\n",
    "\n",
    "def select_clf(ki,base):\n",
    "    if(ki==0):\n",
    "        clf=sklearn.tree.DecisionTreeClassifier\n",
    "        order=base+['max_features','max_depth']\n",
    "    elif(ki==1):\n",
    "        clf=sklearn.naive_bayes.GaussianNB\n",
    "        order=base+[]\n",
    "    elif(ki==2):\n",
    "        clf=sklearn.neighbors.KNeighborsClassifier\n",
    "        order=base+['n_neighbors','weights']\n",
    "    elif(ki==3):\n",
    "        clf=sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "        order=base+['solver','shrinkage']\n",
    "    elif(ki==4):\n",
    "        clf=sklearn.neural_network.MLPClassifier\n",
    "        order=base+['alpha','hidden_layer_sizes']\n",
    "    elif(ki==5):\n",
    "        clf=sklearn.svm.SVC\n",
    "        order=base+['cache_size','kernel','C','gamma']\n",
    "    return clf,order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}